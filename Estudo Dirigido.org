#+OPTIONS: toc:nil num:nil

* Pesquisa para Estudo Dirigido II
** Proposta
    - Aplicar o conceito de aproximação local do LIME, mas ao invés de usar um modelo linear usar a entropia condicional (Informação mútua: I(Y|X)) das respostas do modelo.
*** TODO Qual a diferença? Vantagens e desvantagens?
    - [[https://stats.stackexchange.com/questions/360022/how-does-lime-compares-with-mutual-information][Pergunta no CV]] 
*** O LIME usa modelos lineares e define \omega(g) como o número de coeficientes não-nulos
    - Seria possível usar aproximações de grau maior? Como interpretar?
*** Usar a Informação Mútua com as distribuições "discretizadas"? Ou usar aproximações para as distribuições contínuas?
** Plano de trabalho
*** Escolher um (ou mais) datasets
*** Treinar um (ou mais) modelos
*** Usar o LIME para explicar algumas instâncias
*** Escrever código para computar a informação mútua de perturbações na instâncias
*** Comparar explicações com as do LIME

* Estratégia de Trabalho
** Fluxo principal
*** Treinar um modelo de ML sobre seus dados
*** Criar um explicador, passando uma interface de previsão (ex: .fit()) e o dataset
**** Explicador faz pré-precessamento
     - É necessário algum? Qual? Pode ser que mude? O código precisa ser flexível o suficiente para permitir isso?
     - Provavelmente pré-computar buckets para as distribuições?
*** Chamar a função de explicação para uma determinada instância
**** Gera perturbações no datapoint
     - Feito no Lime em lime_tabular.py@381 (__data_inverse), tratamentos diferentes para features
       numéricas ("desnormaliza") e categóricas (1 se for igual a instância e 0 cc)[?]
**** Calcula informação mútua sobre a distribuição local
**** Gera um representação interpretável para isso
